# spring23-ITMCS
Notes and resources for the Information-Theoretic Methods in Computer Science in IIIT Hyderabad.

# Weightages
* Assignments – 15
* Quizzes – 10
* Midsem – 20
* Endsem – 40
* Term Paper – 15

# Lecture Contents
* Week 1
    * Lecture 1 (03 January, Tuesday)
        - Introduction
    * Lecture 2 (06 January, Friday)
        - Basics of Probability Theory
            - Random Variables
            - Joint Distribution
            - Conditional Distribution
            - Functions on R.Vs.
            - Expectation
            - Variance
        - Entropy
            - Definition
* Week 2
    * Lecture 3 (10 January, Tuesday)
        - Entropy (contd.)
            - Properties
            - Joint Entropy
            - Conditional Entropy
            - Mutual Information
            - Relative Entropy (KL-Divergence)
    * Lecture 4 (13 January, Friday)
        - Shashwat's notes
* Week 3
    * Lecture 5 (17 January, Tuesday)
        - Entropy (contd.)
            - Subadditivity
            - Fano's Inequality
* Week 4
    * Lecture 6 (21 January, Tuesday)
        - [missed] Questions
    * Lecture 7 (27 January, Friday)
        - Entropy
            - Fano's Inequality (contd.)
        - Source Coding
* Week 5
    * Lecture 8 (31 January, Tuesday)
        - Source Coding (contd.)
* Week 6
    * Lecture 9 (07 February, Tuesday)
        - Connection between Entropy and Counting
            - Sorting
            - Binomial Coefficients
    * Lecture 10 (10 February, Friday)
        - Connection between Entropy and Counting
            - Binomial Coefficients (contd.)
            - Repetitions in Matrices
* Week 7
    * Lecture 11 (14 February, Tuesday)
        - Connection between Entropy and Counting
            - Repetitions in Matrices (contd.)
            - Shearer's Lemma
            - Loomis-Whitney Inequality
    * Lecture 12 (17 February, Friday)
        - Connections between Entropy and Counting
            - Loomis-Whitney Inequality (contd.)
            - Shearer's Lemma
* Week 8
    * Lecture 13 (21 February, Tuesday)
        - Connections between Entropy and Counting
            - Shearer's Lemma (contd.)
            - Bregman's Theorem
    * Lecture 14 (24 February, Friday)
        - Connections between Entropy and Counting
            - Bregman's Theorem (contd.)
* Week 9
    * Lecture 15 (03 March, Friday)
        - Connections between Entropy and Counting
            - Bregman's Theorem (contd.)
* Week 10
    * Lecture 16 (10 March, Friday)
        - Connections between Entropy and Counting
            - Bregman's Theorem (contd.)
* Week 11
    * Lecture 17 (14 March, Tuesday)
        - Entropy for Continuous Random Variables
            - Mutual Information
            - Quantisation
* Week 12
    * Lecture 18 (21 March, Tuesday)
        - Entropy for Continuous Random Variables
            - Quantisation (contd.)
            - Scaling
        - Total Variational Distance
    * Lecture 19 (24 March, Friday)
        - Total Variational Distance (contd.)
            - Pinsker's Inequality
            - Chain Rule of Relative Entropy
            - Pinsker's Inequality (contd.)
* Week 13
    * Lecture 20 (28 March, Tuesday)
        - Total Variational Distance
            - Pinsker's Inequality (contd.)
            - Distinguishing Coins
    * Lecture 21 (31 March, Friday)
        - Total Variational Distance
            - Distinguishing Coins (contd.)
                - Optimality of the Lower Bound
                - Chernoff Bound
                - Optimality of the Lower Bound (contd.)
* Week 15
    * Lecture 22 (11 April, Tuesday)
        - Information Leakage
            - Conditions for Leakage Measures
            - Guessing Framework
    * Lecture 23 (14 April, Friday)
        - Information Leakage
            - Guessing Framework (contd.)
* Week 16
    * Lecture 24 (18 April, Tuesday)